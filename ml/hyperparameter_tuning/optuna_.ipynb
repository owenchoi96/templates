{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZaAvp7imqKO"
      },
      "outputs": [],
      "source": [
        "!pip install -q optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_lgb(trial):\n",
        "    params = {\n",
        "        'max_depth' : trial.suggest_int('max_depth', 2, 11),\n",
        "        'scale_pos_weight' : trial.suggest_float('scale_pos_weight', def_scale_pos_weight/2, def_scale_pos_weight*2),\n",
        "        'reg_lambda' : trial.suggest_float('reg_lambda', 1e-8, 10.0, log=True),\n",
        "        'reg_alpha' : trial.suggest_float('reg_alpha', 1e-8, 10.0, log=True)\n",
        "    }\n",
        "    if params['max_depth'] == 11:\n",
        "        params['max_depth'] = -1\n",
        "\n",
        "    # 모델 원형\n",
        "    clf = lgb.LGBMClassifier(random_state=rand, n_jobs=-1, **params) # 이중 참조\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    metrics_dict = evaluate_class_mdl(clf, X_train, X_test, y_train, y_test, plot=False)\n",
        "\n",
        "    # optimize를 위한 최소조건을 준다는 의미\n",
        "    if (metrics_dict['tn%'] < min_tn) or (metrics_dict['fp%'] > max_fp):\n",
        "        return 0\n",
        "\n",
        "    return metrics_dict['recall']\n",
        "\n",
        "%%time\n",
        "opt_study = optuna.create_study(direction='maximize')\n",
        "opt_study.optimize(optimize_lgb, n_trials=100)\n",
        "\n",
        "# best_params\n",
        "opt_study.best_params"
      ],
      "metadata": {
        "id": "vCiQXENGmvXj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}