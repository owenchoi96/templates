{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# from titanic"
      ],
      "metadata": {
        "id": "NvfGISMOQ0Nv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsKF4d9uNAm2"
      },
      "outputs": [],
      "source": [
        "# -- preprocessing process summary --\n",
        "\n",
        "# missing values function\n",
        "from copy import deepcopy\n",
        "\n",
        "def preprocess(sample: pd.Series):\n",
        "    sample = deepcopy(sample)\n",
        "\n",
        "    sample.drop('Cabin', inplace=True)\n",
        "\n",
        "    sample['Age'] = 28 if pd.isna(sample['Age']) else sample['Age']\n",
        "    sample['Embarked'] = 'S' if pd.isna(sample['Embarked']) else sample['Embarked']\n",
        "    return sample\n",
        "\n",
        "# preprocessing function\n",
        "\n",
        "def to_onehot(sample, target, id_to_label):\n",
        "    feature = {}\n",
        "    for label in id_to_label:\n",
        "        if label == sample[target]:\n",
        "            feature[f'{target}__{label}'] = 1\n",
        "        else:\n",
        "            feature[f'{target}__{label}'] = 0\n",
        "    return feature\n",
        "\n",
        "def normalize(val, min_val, max_val):\n",
        "    return (val - min_val)/(max_val - min_val)\n",
        "\n",
        "def to_feature(sample: pd.Series):\n",
        "    feature = {}\n",
        "\n",
        "    # Sex\n",
        "    global sex_to_id\n",
        "    feature['Sex'] = sex_to_id[sample['Sex']]\n",
        "\n",
        "    # Embarked\n",
        "    global id_to_embarked\n",
        "    feature.update(to_onehot(sample, 'Embarked', id_to_embarked))\n",
        "\n",
        "    # Pclass\n",
        "    global pclass_min, pclass_max\n",
        "    feature['Pclass'] = normalize(sample['Pclass'], pclass_min, pclass_max)\n",
        "\n",
        "    # Age\n",
        "    # bucketing\n",
        "    global age_min, age_max\n",
        "    feature['Age'] = normalize(sample['Age'] // 5, age_min, age_max)\n",
        "\n",
        "    # Sibsp\n",
        "    global sibsp_min, sibsp_max\n",
        "    feature['SibSp'] = normalize(sample['SibSp'], sibsp_min, sibsp_max)\n",
        "    # Parch\n",
        "    global parch_min, parch_max\n",
        "    feature['Parch'] = normalize(sample['Parch'], parch_min, parch_max)\n",
        "    # Fare\n",
        "    global fare_min, fare_max\n",
        "    feature['Fare'] = normalize(sample['Fare'], fare_min, fare_max)\n",
        "\n",
        "    if 'Survived' in sample:\n",
        "        feature['Survived'] = sample['Survived']\n",
        "\n",
        "\n",
        "    return pd.Series(feature)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/수강생 강의 자료/Step 1. 자연어처리에 필요한 기본 수학지식 및 딥러닝 기초/Data/titanic/train.csv')\n",
        "\n",
        "# filling missing values\n",
        "age_to_fill = df['Age'].median(skipna=True)\n",
        "df['Age'] = df['Age'].fillna(age_to_fill)\n",
        "age_to_fill = df['Age'].median(skipna=True)\n",
        "df['Age'] = df['Age'].fillna(age_to_fill)\n",
        "df['Embarked'].fillna(df['Embarked'].value_counts().idxmax(), inplace=True)\n",
        "\n",
        "# texts to numbers\n",
        "sex_to_id = {k:i for i, k in enumerate(df['Sex'].unique())} # Sex\n",
        "id_to_embarked = list(df['Embarked'].unique()) # Embarked\n",
        "\n",
        "# getting min, max values for MinMax scaling\n",
        "age_min, age_max = 0, df['Age'].max() // 5 # Age\n",
        "sibsp_min, sibsp_max = df['SibSp'].min(), df['SibSp'].max() # SibSp\n",
        "parch_min, parch_max = df['Parch'].min(), df['Parch'].max() # Parch\n",
        "fare_min, fare_max = df['Fare'].min(), df['Fare'].max() # Fare\n",
        "pclass_min, pclass_max = df['Pclass'].min(), df['Pclass'].max() # Pclass\n",
        "\n",
        "# reading csv file and applying preprocessing functions\n",
        "df = df.apply(lambda sample : to_feature(preprocess(sample)), axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "SNS4MtElNF7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from house prices"
      ],
      "metadata": {
        "id": "EuTbizTRQ1qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- checking binary variable --\n",
        "binary_var = []\n",
        "for k in df.keys():\n",
        "    if len(df[k].unique()) == 2:\n",
        "        binary_var.append(k)\n",
        "\n",
        "# -- grouping variables --\n",
        "binary_category_key_list = ['Street', 'CentralAir']\n",
        "multi_category_key_list = ['MSSubClass', 'MSZoning']\n",
        "numerical_discrete_key_list = ['LotArea', 'GrLiveArea', 'LotFrontage']\n"
      ],
      "metadata": {
        "id": "Sucy4szCQ8H_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- preprocess &  to_feature --\n",
        "from copy import deepcopy\n",
        "\n",
        "def preprocess(sample: pd.Series):\n",
        "    vars_to_use = ['LotArea', 'GrLivArea', 'LotFrontage', 'MSSubClass',\n",
        "                   'MSZoning', 'Street', 'CentralAir', 'SalePrice']\n",
        "    sample = deepcopy(sample[vars_to_use])\n",
        "    sample['LotFrontage'] = 69.0 if pd.isna(sample['LotFrontage']) else sample['LotFrontage']\n",
        "    return sample\n",
        "\n",
        "def to_onehot(sample, target, id_to_label):\n",
        "    feature = {}\n",
        "\n",
        "    for label in id_to_label:\n",
        "        if label == sample[target]:\n",
        "            feature[f'{target}__{label}'] = 1\n",
        "        else:\n",
        "            feature[f'{target}__{label}'] = 0\n",
        "    return feature\n",
        "\n",
        "def normalize(val, val_mean, val_std):\n",
        "    return (val - val_mean)/val_std\n",
        "\n",
        "def to_feature(sample: pd.Series):\n",
        "    feature = {}\n",
        "\n",
        "    # Street\n",
        "    global street_to_id\n",
        "    feature['Street'] = street_to_id[sample['Street']]\n",
        "\n",
        "    # CentralAir\n",
        "    global center_air_to_id\n",
        "    feature['CentralAir'] = center_air_to_id[sample['CentralAir']]\n",
        "\n",
        "    # MSSubClass\n",
        "    global id_to_mssubclass\n",
        "    feature.update(to_onehot(sample, 'MSSubClass', id_to_mssubclass))\n",
        "\n",
        "    # MSZoning\n",
        "    global id_to_mszoning\n",
        "    feature.update(to_onehot(sample, 'MSZoning', id_to_mszoning))\n",
        "\n",
        "    # LotArea\n",
        "    global lotarea_mean , lotarea_std\n",
        "    feature['LotArea'] = normalize(sample['LotArea'], lotarea_mean, lotarea_std)\n",
        "\n",
        "    # GrLivArea\n",
        "    global grlivearea_mean , grlivearea_std\n",
        "    feature['GrLivArea'] = normalize(sample['GrLivArea'], grlivearea_mean, grlivearea_std)\n",
        "\n",
        "    # LotFrontage\n",
        "    global lotfrontage_mean, lotfrontage_std\n",
        "    feature['LotFrontage'] = normalize(sample['LotFrontage'], lotfrontage_mean, lotfrontage_std)\n",
        "\n",
        "    if 'SalePrice' in sample:\n",
        "        feature['SalePrice'] = sample['SalePrice']\n",
        "\n",
        "    return pd.Series(feature)\n",
        "\n",
        "# binary categorical variables\n",
        "street_to_id = {k:i for i, k in enumerate(df['Street'].unique())}\n",
        "center_air_to_id = {k:i for i, k in enumerate(df['CentralAir'].unique())}\n",
        "\n",
        "# multiple categorical variables\n",
        "id_to_mssubclass = list(df['MSSubClass'].unique())\n",
        "id_to_mszoning = list(df['MSZoning'].unique())\n",
        "\n",
        "# numerical variables\n",
        "lotarea_mean , lotarea_std = df['LotArea'].mean(), df['LotArea'].std()\n",
        "grlivearea_mean , grlivearea_std = df['GrLivArea'].mean(), df['GrLivArea'].std()\n",
        "lotfrontage_mean, lotfrontage_std = df['LotFrontage'].mean(), df['LotFrontage'].std()\n",
        "\n",
        "df = pd.read_csv(data_path)\n",
        "df = df.apply(lambda sample: to_feature(preprocess(sample)), axis=1)"
      ],
      "metadata": {
        "id": "C4iwkBldj6o_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}