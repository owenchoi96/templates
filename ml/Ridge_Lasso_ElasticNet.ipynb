{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xs9aVc7XV8To"
      },
      "outputs": [],
      "source": [
        "# Ridge Regression\n",
        "    # overfitting 방지\n",
        "    # 다중공선성 방지\n",
        "    # scaling 필수\n",
        "    # -- parameters --\n",
        "        # alpha : L2-norm penalty term\n",
        "        # fit_intercept : centering to zero\n",
        "        # max_iter : maximum number of iteration\n",
        "\n",
        "# package\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# option 1 : for loop\n",
        "penalty = [.00001, .00005 ,.0001, .001, .01, .1, .3, .5, .6, .7, .9, 1, 10]\n",
        "\n",
        "for a in penalty:\n",
        "    model = Ridge(alpha=a).fit(X_scal.iloc[train_idx], Y.iloc[train_idx])\n",
        "    score = model.score(X_scal.iloc[valid_idx], Y.iloc[valid_idx])\n",
        "    pred_y = model.predict(X_scal.iloc[valid_idx])\n",
        "    mse = mean_squared_error(Y.iloc[valid_idx], pred_y)\n",
        "    print(\"Alpha : {:.5f} --> R2 : {:.7f} / MSE : {:.7f} /RMSE : {:.7f}\\n\".format(a, score, mse, np.sqrt(mse)))\n",
        "\n",
        "# option2 : GridSearchCV\n",
        "ridge_cv = RidgeCV(alphas=penalty, cv=5)\n",
        "model = ridge_cv.fit(X_scal.iloc[train_idx], Y.iloc[train_idx])\n",
        "print('best alpha : {:.5f}, R2 : {:.4f}'.format(model.alpha_, model.best_score_))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lasso Regression\n",
        "    # scaling 필수\n",
        "    # feature selection 가능\n",
        "    # 다중공선성이 있는 데이터에 대해서는 좋은 성능 X\n",
        "    # -- parameters --\n",
        "        # alpha : L1-norm penlty term\n",
        "        # fit_intercept : centering to zero\n",
        "        # max_iter : maximum number of iteration\n",
        "\n",
        "# package\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import Lasso, LassoCV\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# option 1 : for loop\n",
        "penalty = [.00001, .00005 ,.0001, .001, .01, .1, .3, .5, .6, .7, .9, 1, 10]\n",
        "\n",
        "for a in penalty:\n",
        "    model = Lasso(alpha=a).fit(X_scal.iloc[train_idx], Y.iloc[train_idx])\n",
        "    score = model.score(X_scal.iloc[valid_idx], Y.iloc[valid_idx])\n",
        "    pred_y = model.predict(X_scal.iloc[valid_idx])\n",
        "    mse = mean_squared_error(Y.iloc[valid_idx], pred_y)\n",
        "    print(\"Alpha : {:.5f} --> R2 : {:.7f} / MSE : {:.7f} /RMSE : {:.7f}\\n\".format(a, score, mse, np.sqrt(mse)))\n",
        "\n",
        "# option2 : GridSearchCV\n",
        "ridge_cv = LassoCV(alphas=penalty, cv=5)\n",
        "model = ridge_cv.fit(X_scal.iloc[train_idx], Y.iloc[train_idx])\n",
        "print('best alpha : {:.5f}, R2 : {:.4f}'.format(model.alpha_, model.best_score_))"
      ],
      "metadata": {
        "id": "_GFY3uQAdC3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ElasticNet\n",
        "    # scaling 필수\n",
        "    # L2-norm (Ridge)와 L1-norm (Lasso)을 섞어놓음\n",
        "    # -- parameters --\n",
        "        # alpha : L2-norm penalty term -> 0 : Linear Regression\n",
        "        # l1_ratio : L1-norm penalty term -> 0 <= l1_ratio <= 1, 1 : Ridge Regression\n",
        "        # fit_intercept : centering to zero\n",
        "        # max_iter : maximum number of iteration\n",
        "\n",
        "# package\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# option 1 : for loop\n",
        "\n",
        "# alpha\n",
        "# close to 0 -> linear regression\n",
        "alphas = [.000001, .000005 ,.00001, .00005, .0001, .001, .005, .01, .05]\n",
        "\n",
        "# l1_ratio\n",
        "# close to 1 -> Lasso, close to 0 -> Ridge\n",
        "l1_ratio = [.9, .7, .5, .3, .1]\n",
        "\n",
        "for a in alphas:\n",
        "    for b in l1_ratio:\n",
        "        model = ElasticNet(alpha=a, l1_ratio=b).fit(X_scal.iloc[train_idx], Y.iloc[train_idx])\n",
        "        score = model.score(X_scal.iloc[valid_idx], Y.iloc[valid_idx])\n",
        "        pred_y = model.predict(X_scal.iloc[valid_idx])\n",
        "        mse = mean_squared_error(Y.iloc[valid_idx], pred_y)\n",
        "        print(\"Alpha : {:.7f}, lr_ratio : {:.7f} --> R2 : {:.7f} / MSE : {:.7f} /RMSE : {:.7f}\".format(a, b, score, mse, np.sqrt(mse)))\n",
        "\n",
        "# option 2 : GridSearchCV\n",
        "\n",
        "# dictionary for grid\n",
        "grid = dict()\n",
        "grid['alpha'] = alphas\n",
        "grid['l1_ratio'] = l1_ratio\n",
        "\n",
        "# model and grid search preparation\n",
        "model = ElasticNet()\n",
        "search = GridSearchCV(model, grid, scoring='neg_root_mean_squared_error', cv=5, n_jobs=-1)\n",
        "results = search.fit(X_scal.iloc[valid_idx], Y.loc[valid_idx])\n",
        "\n",
        "# summarize\n",
        "print('RMSE : {:.4f}'.format(results.best_score_))\n",
        "print('Config : {}'.format(results.best_params_))\n"
      ],
      "metadata": {
        "id": "w33tIkKwdnhI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}