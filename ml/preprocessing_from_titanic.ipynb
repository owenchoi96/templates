{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rsKF4d9uNAm2"
      },
      "outputs": [],
      "source": [
        "# -- preprocessing process summary --\n",
        "\n",
        "# missing values function\n",
        "from copy import deepcopy\n",
        "\n",
        "def preprocess(sample: pd.Series):\n",
        "    sample = deepcopy(sample)\n",
        "\n",
        "    sample.drop('Cabin', inplace=True)\n",
        "\n",
        "    sample['Age'] = 28 if pd.isna(sample['Age']) else sample['Age']\n",
        "    sample['Embarked'] = 'S' if pd.isna(sample['Embarked']) else sample['Embarked']\n",
        "    return sample\n",
        "\n",
        "# preprocessing function\n",
        "\n",
        "def to_onehot(sample, target, id_to_label):\n",
        "    feature = {}\n",
        "    for label in id_to_label:\n",
        "        if label == sample[target]:\n",
        "            feature[f'{target}__{label}'] = 1\n",
        "        else:\n",
        "            feature[f'{target}__{label}'] = 0\n",
        "    return feature\n",
        "\n",
        "def normalize(val, min_val, max_val):\n",
        "    return (val - min_val)/(max_val - min_val)\n",
        "\n",
        "def to_feature(sample: pd.Series):\n",
        "    feature = {}\n",
        "\n",
        "    # Sex\n",
        "    global sex_to_id\n",
        "    feature['Sex'] = sex_to_id[sample['Sex']]\n",
        "\n",
        "    # Embarked\n",
        "    global id_to_embarked\n",
        "    feature.update(to_onehot(sample, 'Embarked', id_to_embarked))\n",
        "\n",
        "    # Pclass\n",
        "    global pclass_min, pclass_max\n",
        "    feature['Pclass'] = normalize(sample['Pclass'], pclass_min, pclass_max)\n",
        "\n",
        "    # Age\n",
        "    # bucketing\n",
        "    global age_min, age_max\n",
        "    feature['Age'] = normalize(sample['Age'] // 5, age_min, age_max)\n",
        "\n",
        "    # Sibsp\n",
        "    global sibsp_min, sibsp_max\n",
        "    feature['SibSp'] = normalize(sample['SibSp'], sibsp_min, sibsp_max)\n",
        "    # Parch\n",
        "    global parch_min, parch_max\n",
        "    feature['Parch'] = normalize(sample['Parch'], parch_min, parch_max)\n",
        "    # Fare\n",
        "    global fare_min, fare_max\n",
        "    feature['Fare'] = normalize(sample['Fare'], fare_min, fare_max)\n",
        "\n",
        "    if 'Survived' in sample:\n",
        "        feature['Survived'] = sample['Survived']\n",
        "\n",
        "\n",
        "    return pd.Series(feature)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/수강생 강의 자료/Step 1. 자연어처리에 필요한 기본 수학지식 및 딥러닝 기초/Data/titanic/train.csv')\n",
        "\n",
        "# filling missing values\n",
        "age_to_fill = df['Age'].median(skipna=True)\n",
        "df['Age'] = df['Age'].fillna(age_to_fill)\n",
        "age_to_fill = df['Age'].median(skipna=True)\n",
        "df['Age'] = df['Age'].fillna(age_to_fill)\n",
        "df['Embarked'].fillna(df['Embarked'].value_counts().idxmax(), inplace=True)\n",
        "\n",
        "# texts to numbers\n",
        "sex_to_id = {k:i for i, k in enumerate(df['Sex'].unique())} # Sex\n",
        "id_to_embarked = list(df['Embarked'].unique()) # Embarked\n",
        "\n",
        "# getting min, max values for MinMax scaling\n",
        "age_min, age_max = 0, df['Age'].max() // 5 # Age\n",
        "sibsp_min, sibsp_max = df['SibSp'].min(), df['SibSp'].max() # SibSp\n",
        "parch_min, parch_max = df['Parch'].min(), df['Parch'].max() # Parch\n",
        "fare_min, fare_max = df['Fare'].min(), df['Fare'].max() # Fare\n",
        "pclass_min, pclass_max = df['Pclass'].min(), df['Pclass'].max() # Pclass\n",
        "\n",
        "# reading csv file and applying preprocessing functions\n",
        "df = df.apply(lambda sample : to_feature(preprocess(sample)), axis=1)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "SNS4MtElNF7Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}