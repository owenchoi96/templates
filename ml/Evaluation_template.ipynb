{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-PIk-Z4mTVQ"
      },
      "outputs": [],
      "source": [
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "\n",
        "# evaluation 함수 정의 --> fitted model이 들어와야 함\n",
        "def evaluate_class_mdl(fitted_model, X_train, X_test, y_train, y_test, plot=True, pct=True, thresh=.5):\n",
        "    y_train_pred = fitted_model.predict(X_train).squeeze()\n",
        "    if len(np.unique(y_train_pred)) > 2:\n",
        "        y_train_pred = np.where(y_train_pred > thresh, 1, 0)\n",
        "        y_test_prob = fitted_model.predict(X_test).squeeze()\n",
        "        y_test_pred = np.where(y_test_pred > thres, 1, 0)\n",
        "    else:\n",
        "        y_test_prob = fitted_model.predict_proba(X_test)[:, 1]\n",
        "        y_test_pred = np.where(y_test_prob > thresh, 1, 0)\n",
        "    roc_auc_te = metrics.roc_auc_score(y_test, y_test_prob)\n",
        "\n",
        "    cf_matrix = metrics.confusion_matrix(y_test, y_test_pred)\n",
        "    tn, fp, fn, tp = cf_matrix.ravel()\n",
        "    acc_tr = metrics.accuracy_score(y_train, y_train_pred)\n",
        "    acc_te = metrics.accuracy_score(y_test, y_test_pred)\n",
        "    pre_te = metrics.precision_score(y_test, y_test_pred)\n",
        "    rec_te = metrics.recall_score(y_test, y_test_pred)\n",
        "    f1_te = metrics.f1_score(y_test, y_test_pred)\n",
        "    mcc_te = metrics.matthews_corrcoef(y_test, y_test_pred)\n",
        "\n",
        "    if plot:\n",
        "        print(f'Accuracy_train : {acc_tr: .4f}\\t\\tAccuracy_test : {acc_te: .4f}')\n",
        "        print(f'Precision_test : {pre_te: .4f}\\t\\tRecall_test : {rec_te: .4f}')\n",
        "        print(f'ROC-AUC_test : {roc_auc_te: .4f}\\t\\tF1_test : {f1_te: .4f}\\t\\tMCC_test : {mcc_te: .4f}')\n",
        "        if pct: # normalize 할지 말지\n",
        "            ax = sns.heatmap(cf_matrix/np.sum(cf_matrix), annot=True,\n",
        "                             fmt='.2%', cmap='Blues', annot_kws={'size':16})\n",
        "        else:\n",
        "            ax = sns.heatmap(cf_matrix, annot=True,\n",
        "                             fmt='d', cmap='Blues', annot_kws={'size':16})\n",
        "        ax.set_xlabel('Predicted', fontsize=12)\n",
        "        ax.set_ylabel('Observed', fontsize=12)\n",
        "        plt.show()\n",
        "\n",
        "        return y_train_pred, y_test_prob, y_test_pred\n",
        "    else:\n",
        "        t = cf_matrix.sum()\n",
        "        metrics_dict = {\n",
        "            'accuracy_train' : acc_tr,\n",
        "            'accuracy_test' : acc_te,\n",
        "            'precision' : pre_te,\n",
        "            'recall' : rec_te,\n",
        "            'roc_auc' : roc_auc_te,\n",
        "            'f1' : f1_te,\n",
        "            'mcc' : mcc_te,\n",
        "            'tn%' : tn/t,\n",
        "            'fp%' : fp/t,\n",
        "            'fn%' : fn/t,\n",
        "            'tp%' : tp/t\n",
        "        }\n",
        "        return metrics_dict"
      ]
    }
  ]
}