{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bwhfEOkIQcGJ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split()\n",
        "\n",
        "# after spliting data\n",
        "# Transpose --> feature(column)이 행으로 오게 됨\n",
        "# 'y_train == '으로 분리가 가능\n",
        "X_train.T[0][y_train==0] # binary classification의 경우 negative label\n",
        "X_train.T[0][y_train==1] # binary classification의 경우 positive label"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# histogram while spliting between 0 and 1\n",
        "fig, ax = plt.subplots(15, 2, figsize=(20,70))\n",
        "for i, feat in enumerate(X_train.T): # 꼭 transpose 해야됨\n",
        "\n",
        "    sns.distplot(feat[y_train==0], ax=ax.flat[i], # label --> 0\n",
        "                 label='{} : {}'.format(np.unique(df['diagnosis'])[0],\n",
        "                                        len(y_train[y_train==0])))\n",
        "    sns.distplot(feat[y_train==1], ax=ax.flat[i], # label --> 1\n",
        "                 label='{} : {}'.format(np.unique(df['diagnosis'])[1],\n",
        "                                        len(y_train[y_train==1])))\n",
        "\n",
        "    ax.flat[i].set_title('{} : / mean : {} / std : {}'.format(list(df.iloc[:, 2:].columns)[i],\n",
        "                                                              abs(feat.mean().round(2)),\n",
        "                                                              feat.std().round(2)))\n",
        "    ax.flat[i].legend()\n",
        "plt.tight_layout()"
      ],
      "metadata": {
        "id": "LQB1sx8320_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    <해석>\n",
        "\n",
        "    * histogram을 보고 분산을 통해 feature가 도움이 될지 안될지 어느정도 예측 가능\n",
        "      Ex) 한 feature 다른 레이블 (0&1)의 분포가 서로 많이 떨어져 있으면 맞출 확률이 높아질 것으로 예상가능 (명확하게 구분되는 것 등이 있는지 확인)\n",
        "          vs. 반대로 많이 겹쳐있으면 중간에 겹치는 애들은 많이 못 맞출 것으로 예상할 수 있음\n",
        "\n",
        "    * 하지만, feature 2개 이상이 들어갔을 때는 상관관계로 인해 달라질 수 있으므로, 참고자료로 활용 가능."
      ],
      "metadata": {
        "id": "m2qeSSIl273m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}