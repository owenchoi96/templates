{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "    <EDA process for feature selection>\n",
        "\n",
        "    * categorical\n",
        "        1) chisquare-test\n",
        "        2) OptimalBinning\n",
        "\n",
        "    * numeric\n",
        "        1) ANOVA & Kruskall-wallis test\n",
        "            * 사용하기 전에\n",
        "                - 실습에서는 독립형 변수가 numeric일 때 & 종속변수가 categorical 일 때, 혹은\n",
        "                  독립형 변수가 categorical 일 때 & 종속변수가 numeric일 때 사용함\n",
        "                - 하지만 둘다 numeric일때 사용하지는 않음\n",
        "                - 때문에 이 부분을 잘 유념하고 사용할 수 있도록 하기\n",
        "            * ANOVA (3 prerequisite tests)\n",
        "                * 정규성 검정\n",
        "                    - qqplot\n",
        "                    - shapiro-wilks test\n",
        "                * 등분산성 검정\n",
        "                    - 정규성 검정 만족해야 함\n",
        "                    - 하지만 현실 데이터에서는 정규성을 만족하는 경우가 많지 않음\n",
        "                    - 그러면 box-cox 변환 등을 사용하여 데이터 스케일링 후 다시 검정해보는 경우가 있음\n",
        "                * 독립성 검정\n",
        "            * Kruskall-wallis test\n",
        "\n",
        "        2) OptimalBinning\n",
        "        3) VIF\n",
        "        4) Correlation & Heatmap\n",
        "        5) skew, kurtosis check"
      ],
      "metadata": {
        "id": "aEO2nkIIindK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "    1) categorical variables"
      ],
      "metadata": {
        "id": "_QoGbtS8jSLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prerequisites\n",
        "\n",
        "target_column = ''\n",
        "list_categorical_columns = []"
      ],
      "metadata": {
        "id": "R7T1qqzxoTQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- chi2square-test --\n",
        "# classification에 활용\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "list_meaningful_column_by_chi2 = []\n",
        "for column_name in list_categorical_columns:\n",
        "    statistic, p_value, _, _ = chi2_contingency(pd.crosstab(df[target_column], df[column_name]))\n",
        "    if p_value < 0.05: # 의미가 없다는 귀무가설 기각시\n",
        "        list_meaningful_column_by_chi2.append(column_name)\n",
        "    print('column: {}, statistic: {}, p_value: {}'.format(column_name, statistic, p_value))\n",
        "print('# of categorical columns before: ', len(list_categorical_columns))\n",
        "print('# of selected columns after chi2: ', len(list_meaningful_column_by_chi2))\n",
        "\n",
        "# -- OptimalBinning --\n",
        "# classification 문제에서 사용 가능\n",
        "# !pip install -q optbinning\n",
        "from optbinning import OptimalBinning\n",
        "import warnings; warnings.filterwarngins('ignore')\n",
        "\n",
        "iv_df = []\n",
        "\n",
        "for i in list_categorical_columns:\n",
        "    variable = i\n",
        "    x = df[variable].values\n",
        "    y = df.credit\n",
        "\n",
        "    optb = OptimalBinning(name=variable,\n",
        "                          dtype='categorical',\n",
        "                          solver='cp',\n",
        "                          )\n",
        "    optb.fit(x,y)\n",
        "\n",
        "    binngin_table = optb.binning_table\n",
        "    v1 = binning_table.build()\n",
        "\n",
        "    loop_df = pd.DataFrame({'val' : variable,\n",
        "                            'IV' : [v1.loc['Totals', 'IV']]})\n",
        "    iv_df.append(loop_df)\n",
        "\n",
        "iv_df = pd.concat(iv_df).reset_index(drop=True)\n",
        "iv_df.sort_values(by=['IV'], ascending=False)\n"
      ],
      "metadata": {
        "id": "OhItlmPKjX59"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "    2) numeric variables"
      ],
      "metadata": {
        "id": "j1sqN_najVsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prerequisites\n",
        "target_columns = ''\n",
        "list_numeric_columns = []"
      ],
      "metadata": {
        "id": "sIXAbsg2wbJi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# -- ANOVA --\n",
        "\n",
        "# 정규성 검정\n",
        "# 1. qqplot 그려보기\n",
        "import stats\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "x = 1\n",
        "plt.subplots_adjust(top=.99, bottom=.01, hspace=.2, wspace=.2)\n",
        "for column_name in list_numeric_columns:\n",
        "    plt.subplot(2,3,x)\n",
        "    x = x+1\n",
        "    stats.probplot(df[column_name], dist=stats.norm, plot=plt)\n",
        "    plt.title(column_name)\n",
        "plt.show()\n",
        "\n",
        "# 2. shapiro-test\n",
        "# 귀무가설: 해당 데이터는 정규분포이다\n",
        "# 대립가설: 해당 데이터는 정규분포가 아니다.\n",
        "for column_name in list_numeric_columns:\n",
        "    statistic, p_value = stats.shapiro(df[column_name])\n",
        "    if p_value >= .05:\n",
        "        print(column_name)\n",
        "print('end')\n",
        "\n",
        "# 등분산성 검정\n",
        "\n",
        "# 독립성 검정\n",
        "\n",
        "# -- Kruskal-wallis --\n",
        "# 정규성 가정이 깨질때 사용\n",
        "from scipy.stats import kruskal\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "list_meaningful_column_by_kruskal = []\n",
        "for column_name in list_numeric_columns:\n",
        "    list_by_value = []\n",
        "    for value in df[column_name].dropna().unique():\n",
        "        df_tmp = df[df[column_name] == value][target_column].dropna()\n",
        "        list_by_value.append(np.array(df_tmp))\n",
        "    statistic, p_value = kruskal(*list_by_value)\n",
        "    if p_value < 0.05: # 의미가 없다는 귀무가설 기각시\n",
        "        list_meaningful_column_by_kruskal.append(column_name)\n",
        "    print('column: {}, statistic: {}, p_value: {}'.format(column_name, statistic, p_value))\n",
        "print('# of numeric columns before: ', len(list_numeric_columns))\n",
        "print('# of selected columns after chi2: ', len(list_meaningful_column_by_kruskal))\n",
        "\n",
        "# -- OptimalBinnig --\n",
        "# classification에서 활용\n",
        "from optbinning import OptimalBinning\n",
        "import warnings; warnings.filterwarngins('ignore')\n",
        "\n",
        "iv_df = []\n",
        "\n",
        "for i in list_numeric_columns:\n",
        "    variable = i\n",
        "    x = df[variable].values\n",
        "    y = df.credit\n",
        "\n",
        "    optb = OptimalBinning(name=variable,\n",
        "                          dtype='numerical',\n",
        "                          solver='cp',\n",
        "                          max_n_prebins=3 # bin이 많아지면 해석이 어려워짐\n",
        "                          )\n",
        "    optb.fit(x,y)\n",
        "\n",
        "    binngin_table = optb.binning_table\n",
        "    v1 = binning_table.build()\n",
        "\n",
        "    loop_df = pd.DataFrame({'val' : variable,\n",
        "                            'IV' : [v1.loc['Totals', 'IV']]})\n",
        "    iv_df.append(loop_df)\n",
        "\n",
        "iv_df = pd.concat(iv_df).reset_index(drop=True)\n",
        "iv_df.sort_values(by=['IV'], ascending=False)\n",
        "\n",
        "# -- correlation & heatmap --\n",
        "\n",
        "# -- VIF --\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "def calculate_vif(df_with_numerical_columns):\n",
        "    vif = pd.DataFrame()\n",
        "    vif['VIF_Factor'] = [variance_inflation_factor(df_with_numerical_columns.values, i) for i in range(df_with_numerical_columns.shape[1])]\n",
        "    vif['Feature'] = df_with_numerical_columns\n",
        "    return vif\n",
        "\n",
        "# vif 값을 보고 다중공선성 판단\n",
        "# ex) > 5, > 10, > 20\n",
        "# 전체적인 컬럼의 다중 공선성이 높은 경우, 임계값을 높이는 경우도 고려 가능\n",
        "df_vif = df[list_numeric_columns].copy()"
      ],
      "metadata": {
        "id": "DETnFaAHpI3v"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}