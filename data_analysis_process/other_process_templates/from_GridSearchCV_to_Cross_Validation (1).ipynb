{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEk9kCw9bBYT"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "from time import time\n",
        "\n",
        "# cross validation score 함수\n",
        "def get_cross_val(clf, X, y, model_name,\n",
        "                  cv_num=5, # 5-Fold\n",
        "                  metric='f1'): # f1-score 기준\n",
        "    scores = cross_val_score(clf, X, y, cv=cv_num, scoring=metric)\n",
        "    mean = scores.mean()\n",
        "    std = scores.std() # 결과에 대한 standard deviation\n",
        "    p025 = np.quantile(scores, 0.025)\n",
        "    p975 = np.quantile(scores, 0.975)\n",
        "    metrics = ['mean', 'stadard deviation', 'p025', 'p975']\n",
        "    s = pd.Series([mean, std, p025, p975],\n",
        "                  index=metrics)\n",
        "    s.name = mo\n",
        "    return s\n",
        "\n",
        "# precision 등의 점수 확인 함수\n",
        "def calculate_metrics(y_true, y_pred, duration, model_name, *args):\n",
        "    acc = accuracy_score(y_true, y_pred) # 현업에서 accuracy는 요즘 많이 안보는데, 베이스라인으로는 보기 좋음\n",
        "    pre = precision_score(y_true, y_pred)\n",
        "    rec = recall_score(y_true, y_pred)\n",
        "    roc_auc = roc_auc_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    ck = cohen_kappa_score(y_true, y_pred)\n",
        "    p, r, fbeta, support = precision_recall_fscore_support(y_true, y_pred)\n",
        "    metrics = ['accuracy', 'precision', 'recall', 'roc_auc', 'f1_score', 'cohen_kappa',\n",
        "               'precision_both', 'recall_both', 'fbeta_both', 'support_both', 'time_to_fit (seconds)']\n",
        "    s = pd.Series([acc, pre, rec, roc_auc, f1, ck, p, r, fbeta, support, duration],\n",
        "                  index=metrics)\n",
        "    s.name = model_name\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic Regression with LogisticRegressionCV\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "\n",
        "# 1. modeling training\n",
        "lr_clf = LogisticRegressionCV(cv=5,\n",
        "                              penalty='elasticnet',\n",
        "                              solver='saga',\n",
        "                              Cs=np.power(10, np.arange(-3, 1, dtype=float)),\n",
        "                              l1_ratios=np.linspace(0, 1, num=6, dtype=float),\n",
        "                              max_iter=100,\n",
        "                              random_state=0)\n",
        "\n",
        "# measuring time\n",
        "# why? --> 모델의 학습시간을 알아야 나중에 현업에서 모델의 훈련시간을 고려할 일이 필요할 때 유용하게 사용 가능\n",
        "start_time = time()\n",
        "lr_clf.fit(X_train_std, y_train)\n",
        "time_elapsed = time() - start\n",
        "\n",
        "# print results\n",
        "print('took {:.2f} seconds for {} cv iterations with {} parameter settings'.format(time_elapsed,\n",
        "                                                                                   lr_clf.n_iter_.shape[1],\n",
        "                                                                                   lr_clf.n_iter_.shape[2]*lr_clf.n_iter_.shape[3]))\n",
        "print('Optimal regularization strength : {}, Optimal L1 ration : {}'.format(lr_clf.C_[0],\n",
        "                                                                            lr_clf.l1_ratio_[0]))\n",
        "print('accuracy (train)', lr_clf.score(X_train_std, y_train))\n",
        "print('accuracy (test)', lr_clf.score(X_test_std, y_test))\n",
        "\n",
        "# 2. cross validation\n",
        "lr_cv = get_cross_val(lr_clf, X_test_std, y_test, 'logistic regression')\n",
        "print(lr_cv.round(2))\n",
        "\n",
        "# 3. confusion matrix\n",
        "y_pred = lr_clf.predict(X_test_std)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                                    display_labels=lr_clf.classes_)\n",
        "cm_display.plot()\n",
        "\n",
        "# 4. classification report\n",
        "# y_pred = lr_clf.predict(X_test_std)\n",
        "print(classification_report(y_test, y_pred,\n",
        "                            target_names=list(np.unique(df['diagnosis']))))\n",
        "\n",
        "lr_metrics = calculate_metrics(y_test, y_pred, time_elasped, 'logistic regression')\n",
        "print('\\n', lr_metrics)"
      ],
      "metadata": {
        "id": "8Vcx33596pu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CV with GridSearchCV\n",
        "# K-Nearest Neighbors / LDA / SVC / Random Forest\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# 1. model training\n",
        "\n",
        "# param_grid\n",
        "\n",
        "# -- KNN --\n",
        "# param_grid = {'weights' : ['uniform', 'distance'],\n",
        "#               'n_neighbors' : np.arange(1,16)}\n",
        "# -- LDA --\n",
        "# param_grid = {'solver' : ['lsqr', 'eigen'],\n",
        "#               'shrinkage' : [None, 'auto'],\n",
        "#               'n_components' : np.arange(1,5)}\n",
        "# -- SVC --\n",
        "# param_grid = {'C' : np.power(10, np.arange(0, 3, dtype=float)),\n",
        "#               'kernel' : ['linear', 'sigmoid', 'rbf'],\n",
        "#               'gamma' : ['auto', 'scale']}\n",
        "# -- RF --\n",
        "# param_grid = {'n_estimators' : np.arange(100, 1000, 200, dtype=int),\n",
        "#               'max_features' : [None, 'sqrt', 'log2'],\n",
        "#               'criterion' : ['gini', 'entropy'],\n",
        "#               'max_depth' : [None, 3, 5, 7]} # depth 지정안하면 무제한으로 들어감 (설정 꼭 필요!)\n",
        "\n",
        "\n",
        "clf =  # classifier name\n",
        "gs_clf = GridSearchCV(clf, param_grid=param_grid)\n",
        "\n",
        "# measuring time\n",
        "start_time = time()\n",
        "gs_clf.fit(X_train_std, y_train)\n",
        "time_elapsed = time() - start\n",
        "\n",
        "# print results\n",
        "print('took {:.2f} seconds for {} candidate parameter settings'.format(time_elapsed,\n",
        "                                                                       len(gs_clf.cv_results_['params'])))\n",
        "print('Optimal  : {}, Optimal  : {}'.format(gs_clf.best_params_[''],\n",
        "                                            gs_clf.best_params_['']))\n",
        "print('accuracy (train)', gs_clf.score(X_train_std, y_train))\n",
        "print('accuracy (test)', gs_clf.score(X_test_std, y_test))\n",
        "print(gs_clf.best_estimator_.get_params())\n",
        "\n",
        "# 2. cross validation\n",
        "clf_cv = get_cross_val(gs_clf, X_test_std, y_test, 'model_name')\n",
        "print(clf_cv.round(2))\n",
        "\n",
        "# 3. confusion matrix\n",
        "y_pred = gs_clf.predict(X_test_std)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "cm_display = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
        "                                    display_labels=gs_clf.classes_)\n",
        "\n",
        "# 4. classification report\n",
        "print(classification_report(y_test, y_pred,\n",
        "                            target_names=list(np.unique(df['target_name']))))\n",
        "\n",
        "clf_metrics = calculate_metrics(y_test, y_pred, time_elasped, 'model_name')\n",
        "print('\\n', clf_metrics)"
      ],
      "metadata": {
        "id": "oUUlr7ai9hKy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}